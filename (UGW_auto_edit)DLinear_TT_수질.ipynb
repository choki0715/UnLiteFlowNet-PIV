{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/choki0715/UnLiteFlowNet-PIV/blob/master/(UGW_auto_edit)DLinear_TT_%EC%88%98%EC%A7%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38af8690-821a-4296-a00b-fa6eefab76f7"
      },
      "source": [
        "<span style=\"color:#ffd33d; font-size:150%\"> 2022.11.07: DLinear Model Demo </span>\n",
        "\n",
        "> 2022.12.08> UGW : TT water quelity : 29파일\n",
        "\n",
        "> 2022.12.09> UGW : TT water quelity : codex 수정 3개 파일, 재정제 3개파일\n",
        "\n",
        "1) encode : 3개\n",
        "\n",
        "2) 재정제 : 3개\n"
      ],
      "id": "38af8690-821a-4296-a00b-fa6eefab76f7"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmKNyZB4kwVC",
        "outputId": "e6753dc5-9954-4aad-a381-eeee1ccfe621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/NIA 2차 수질예측 프로젝트/model/UGW/DLinear\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 이동 복사한 모델 폴더의 경로를 입력하여 이동시킴\n",
        "%cd /content/drive/MyDrive/NIA 2차 수질예측 프로젝트/model/UGW/DLinear"
      ],
      "id": "MmKNyZB4kwVC"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b65ba215-d54c-4d23-a058-cb40e75ffcc2"
      },
      "outputs": [],
      "source": [
        "# import argparse\n",
        "import os\n",
        "import os.path as osp\n",
        "import io\n",
        "import shutil\n",
        "\n",
        "import logging\n",
        "import traceback\n",
        "\n",
        "from datetime import date, datetime\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Set, List, Dict, Tuple #, final\n",
        "from openpyxl import Workbook, load_workbook\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.metrics import *\n",
        "from UGW_exp.exp_main_ugw import Exp_Main\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "import IPython\n",
        "import IPython.display\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (16,12)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "from pickle import FALSE\n",
        "# %matplotlib inline\n",
        "\n",
        "fix_seed = 2022\n",
        "random.seed(fix_seed)\n",
        "torch.manual_seed(fix_seed)\n",
        "np.random.seed(fix_seed)"
      ],
      "id": "b65ba215-d54c-4d23-a058-cb40e75ffcc2"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r8sgv0ZE9Pbj"
      },
      "outputs": [],
      "source": [
        "\n",
        "@dataclass\n",
        "class args:\n",
        "    is_training : bool   # or int\n",
        "    model_id : str\n",
        "    model : str\n",
        "\n",
        "    # data loader\n",
        "    data : str\n",
        "    root_path : str\n",
        "    data_path : str\n",
        "    save_path : str\n",
        "    features : str\n",
        "    target : str\n",
        "    freq : str\n",
        "    checkpoints : str\n",
        "\n",
        "    # forecasting task\n",
        "    seq_len : int         #56\n",
        "    label_len : int       #1\n",
        "    pred_len : int        #5\n",
        "    # DLinear\n",
        "    moving_avg : int      #10\n",
        "    # moving_avg = [3,5,10,15,20,25,30] #,35,40,45]\n",
        "    conv_kernal : int      # 1\n",
        "    conv1d : bool          # True\n",
        "    RIN : bool             # True\n",
        "    combination : bool     # True\n",
        "    embed_type : int       # 0\n",
        "    enc_in : int           # 3\n",
        "    c_out : int       # 1\n",
        "    embed : str       # 'timeF'\n",
        "    do_predict : bool # False\n",
        "\n",
        "    # optimization\n",
        "    num_workers : int          # 10\n",
        "    itr : int                  # 1\n",
        "    train_epochs : int         # 100\n",
        "    batch_size : int           # 5\n",
        "    patience : int             # 7\n",
        "    learning_rate : float      # 0.01\n",
        "    des : str                  # 'Exp'\n",
        "    loss : str                 # 'mse'\n",
        "    lradj : str                # 'type1'\n",
        "    use_amp : bool             # False\n",
        "\n",
        "    # GPU\n",
        "    use_gpu : bool             # True\n",
        "    gpu : int                  # 0\n",
        "    use_multi_gpu : bool       # False\n",
        "    devices : str              # '0,1,2,3'\n",
        "    test_flop : bool           # False\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TS_DATA:\n",
        "    # base info\n",
        "    Id : int\n",
        "    ob_num : str\n",
        "    ob_id : str\n",
        "    ob_name : str\n",
        "    Modi_Date : date\n",
        "    FileName : str\n",
        "    FilePath : str\n",
        "    Row_count : int\n",
        "    MAE : float\n",
        "    MSE : float\n",
        "    RMSE : float\n",
        "    norm_MAPE : float\n",
        "    MAPE : float\n",
        "    ColumnNames : List[str] = field(default_factory=List)\n",
        "    Row_NA_count : List[int] = field(default_factory=List)\n",
        "    plot : bool = False\n",
        "# from openpyxl.styles.fonts import Font\n",
        "\n",
        "class TSFAR:\n",
        "    def __init__(self, file_path, save_path, file_format, fxls_name, sheet_name, sheet_col) -> None:\n",
        "        self.file_path = file_path\n",
        "        self.save_path = save_path\n",
        "        self.file_format = file_format\n",
        "        self.file_list = [f\"{file}\" for file in os.listdir(self.file_path) if self.file_format in file]\n",
        "        self.file_list_len = len(self.file_list)\n",
        "        print(f\" --- Find Files for load : {self.file_list_len}\\n\")\n",
        "        self.TS_DATA_ANLYS_LIST = []\n",
        "        # self.MODEL_args_LIST = []\n",
        "        self.fxls_name = fxls_name\n",
        "        self.sheet_name = sheet_name\n",
        "        # self.sheet_col = sheet_col\n",
        "        self.sheet_col = ['순번','관측정번호','관측망구분','관측망이름','작업일','파일명','파일path','파일행수','MAE','MSE','RMSE','norm_MAPE','MAPE']\n",
        "\n",
        "        self.TSDATA = TS_DATA\n",
        "\n",
        "        logging.basicConfig(filename= self.save_path+'/test.log', level=logging.ERROR)\n",
        "\n",
        "    def TS_DATA_ANLYS_FILES(self):\n",
        "\n",
        "        TSDATA = self.TSDATA\n",
        "\n",
        "        if self.fxls_name in os.listdir(self.file_path):\n",
        "            wb = load_workbook(filename = os.path.join(self.file_path+self.fxls_name))\n",
        "        else:\n",
        "            wb = Workbook()\n",
        "        write_ws = wb.create_sheet(self.sheet_name,-1)\n",
        "        fig_ws = wb.create_sheet(self.sheet_name+'_plot',-1)\n",
        "        write_ws = wb.active\n",
        "        # write_ws.append(self.sheet_col)\n",
        "        colname = ['순번','관측정번호','관측망구분','관측망이름','작업일','파일명','파일path','파일행수','MAE','MSE','RMSE','norm_MAPE','MAPE']\n",
        "        colname.extend([])\n",
        "        write_ws.append(colname)\n",
        "\n",
        "        for file_ix in range(self.file_list_len):\n",
        "            print(f\"\\n=================================================================>> : \")\n",
        "            print(f\"Total Task file Count.... : {self.file_list_len}\")\n",
        "            print(f\"Processing.... Now ...... : {file_ix + 1}\")\n",
        "            print(f\"=================================================================>> : \\n\")\n",
        "\n",
        "            TSDATA = TS_ANLYS(self.file_path, self.file_format, file_ix).Set_TS_Data()\n",
        "\n",
        "            row_max = write_ws.max_row + 1\n",
        "            col_max = write_ws.max_column # need sheet col lenth check\n",
        "            write_ws.cell(row_max,1,TSDATA.Id)\n",
        "            write_ws.cell(row_max,2,TSDATA.ob_num)\n",
        "            write_ws.cell(row_max,3,TSDATA.ob_id)\n",
        "            write_ws.cell(row_max,4,TSDATA.ob_name)\n",
        "            write_ws.cell(row_max,5,TSDATA.Modi_Date)\n",
        "            write_ws.cell(row_max,6,TSDATA.FileName)\n",
        "            write_ws.cell(row_max,7,TSDATA.FilePath)\n",
        "            write_ws.cell(row_max,8,TSDATA.Row_count)\n",
        "            write_ws.cell(row_max,8+1,TSDATA.MAE)\n",
        "            write_ws.cell(row_max,8+2,TSDATA.MSE)\n",
        "            write_ws.cell(row_max,8+3,TSDATA.RMSE)\n",
        "            write_ws.cell(row_max,8+4,TSDATA.norm_MAPE)\n",
        "            write_ws.cell(row_max,8+5,TSDATA.MAPE)\n",
        "            wb.save(os.path.join(self.save_path,self.fxls_name))\n",
        "\n",
        "        return TSDATA\n",
        "\n",
        "\n",
        "class TS_ANLYS:\n",
        "    def __init__(self,file_path, file_format, file_ix) -> None:\n",
        "        self.LOAD_TS_FILE = LOAD_TS_FILE(file_path, file_format, file_ix)\n",
        "        self.file_ix = file_ix\n",
        "        self.Row_count, self.ColumnNames, self.Row_NA_count, self.columns_NA, self.ob_num,self.ob_id, self.ob_name, self.MAE, self.MSE, self.RMSE, self.norm_MAPE, self.MAPE = self.ANLYS()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"TS_ANLYS is called\"\n",
        "\n",
        "    def ANLYS(self):\n",
        "        tsFile_name = self.LOAD_TS_FILE.fileName\n",
        "        tsFile = self.LOAD_TS_FILE.File_loader()\n",
        "        args = self.Set_args()\n",
        "        Exp = Exp_Main\n",
        "\n",
        "        args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "        if args.use_gpu and args.use_multi_gpu:\n",
        "            args.dvices = args.devices.replace(' ', '')\n",
        "            device_ids = args.devices.split(',')\n",
        "            args.device_ids = [int(id_) for id_ in device_ids]\n",
        "            args.gpu = args.device_ids[0]\n",
        "\n",
        "        # OBS_Point = str\n",
        "        Row_count = tsFile.shape[0]\n",
        "        file_info = tsFile_name.rstrip('.csv').split('_')\n",
        "        ob_num = tsFile.iloc[2,0] # tsFile['obsv_no'][2]\n",
        "        ob_id = file_info[0]\n",
        "        ob_name = file_info[1]\n",
        "\n",
        "        Row_NA_count = tsFile.isna().sum().to_list()\n",
        "        # print(f\"Row_NA_count:\\n{type(Row_NA_count)}\")\n",
        "        ColumnNames = tsFile.columns.to_list()\n",
        "        # anlysis info\n",
        "        columns_NA : Tuple[str, int] = field(default_factory=Tuple)\n",
        "        # plot : bool = True\n",
        "\n",
        "        if args.is_training:\n",
        "          for ii in range(args.itr):\n",
        "              # setting record of experiments\n",
        "              setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_eb{}_{}_{}'.format(\n",
        "                                                                    args.model_id, args.model, args.data, args.features,\n",
        "                                                                    args.seq_len, args.label_len, args.pred_len, args.embed,\n",
        "                                                                    args.des, ii)\n",
        "              exp = Exp(args)  # set experiments\n",
        "              print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "              exp.train(setting)\n",
        "\n",
        "              print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "              preds, trues, inputx = exp.test(setting)\n",
        "              MAE, MSE, RMSE, norm_MAPE, MAPE = self.Matric(preds, trues)\n",
        "\n",
        "              if args.do_predict:\n",
        "                  print('>>>>>>>predicting : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "                  exp.predict(setting, True)\n",
        "              torch.cuda.empty_cache()\n",
        "        else:\n",
        "          ii = 0\n",
        "          setting = '{}_{}_{}_ft{}_sl{}_ll{}_pl{}_eb{}_{}_{}'.format(\n",
        "                                                                    args.model_id, args.model, args.data, args.features,\n",
        "                                                                    args.seq_len, args.label_len, args.pred_len, args.embed,\n",
        "                                                                    args.des, ii)\n",
        "          exp = Exp(args)  # set experiments\n",
        "          print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "          preds, trues, inputx = exp.test(setting, test=1)\n",
        "          torch.cuda.empty_cache()\n",
        "          MAE, MSE, RMSE, norm_MAPE, MAPE = self.Matric(preds, trues)\n",
        "\n",
        "        return Row_count, ColumnNames, Row_NA_count, columns_NA, ob_num, ob_id, ob_name, MAE, MSE, RMSE, norm_MAPE, MAPE\n",
        "\n",
        "    def Set_args(self):\n",
        "        tsFile_name = self.LOAD_TS_FILE.fileName\n",
        "        tsFile = self.LOAD_TS_FILE.File_loader()\n",
        "        file_info = tsFile_name.rstrip('.csv').split('_')\n",
        "        ob_num = tsFile.iloc[2,0]\n",
        "        ob_id = file_info[0]\n",
        "        ob_name = file_info[1]\n",
        "\n",
        "\n",
        "        model_args = args(\n",
        "            is_training = True,\n",
        "            model_id = '(UGW)_TT_water_quality_' + str(ob_num) + '_' + str(ob_name),\n",
        "            model = 'DLinear',\n",
        "            # data loader\n",
        "            data = 'UGW_water_quality',\n",
        "            root_path = self.LOAD_TS_FILE.file_path,  #'/content/drive/MyDrive/NIA 2차 수질예측 프로젝트/NIA_AIDEN_06_(지하수)/ AI_데이터_null변환(20220914)/국가수위'\n",
        "            data_path = self.LOAD_TS_FILE.fileName,  # '국가_수위_11742.csv'\n",
        "            save_path = '/content/drive/MyDrive/NIA 2차 수질예측 프로젝트/NIA_AIDEN_07_(지하수)/수질(Total)/plot/',\n",
        "            features = 'MS',\n",
        "            target = 'ec',\n",
        "            freq = 'h',\n",
        "            checkpoints = './(UGW_수질)TT_checkpoints/',\n",
        "            # forecasting task\n",
        "            seq_len = 72,\n",
        "            label_len = 1,\n",
        "            pred_len = 24,\n",
        "            # DLinear\n",
        "            moving_avg = 5,\n",
        "            # args.moving_avg = [3,5,10,15,20,25,30,35,40,45]    # 'window size' list of moving average'\n",
        "            conv_kernal = 1,\n",
        "            conv1d = True,\n",
        "            RIN = True,\n",
        "            combination = True,\n",
        "            embed_type = 0,\n",
        "            enc_in = 5,\n",
        "            c_out = 1,\n",
        "            # self.args.factor = 1\n",
        "            # self.args.distil = True\n",
        "            embed = 'timeF',\n",
        "            # self.args.activation = 'relu'\n",
        "            # self.args.output_attention = True\n",
        "            do_predict = False,\n",
        "            # optimization\n",
        "            num_workers =10,\n",
        "            itr = 1,\n",
        "            train_epochs = 50,\n",
        "            batch_size = 20,\n",
        "            patience = 5,\n",
        "            learning_rate = 0.1,\n",
        "            des = 'Exp',\n",
        "            loss = 'mse',\n",
        "            lradj = 'type1',\n",
        "            use_amp = False ,\n",
        "            # GPU\n",
        "            use_gpu = True,\n",
        "            gpu = 0,\n",
        "            use_multi_gpu = False,\n",
        "            devices = '0,1,2,3',\n",
        "            test_flop = False,\n",
        "        )\n",
        "        return model_args\n",
        "\n",
        "    def Set_TS_Data(self):\n",
        "        TSDATA = TS_DATA(       Id = self.file_ix+1,\n",
        "                                ob_num = self.ob_num,\n",
        "                                ob_id = self.ob_id,\n",
        "                                ob_name = self.ob_name,\n",
        "                                Modi_Date = datetime.today(),\n",
        "                                FileName = self.LOAD_TS_FILE.fileName,\n",
        "                                FilePath = self.LOAD_TS_FILE.file_path,\n",
        "                                Row_count = self.Row_count,\n",
        "                                MAE = self.MAE ,\n",
        "                                MSE = self.MSE,\n",
        "                                RMSE = self.RMSE,\n",
        "                                norm_MAPE = self.norm_MAPE,\n",
        "                                MAPE = self.MAPE,\n",
        "                                ColumnNames = self.ColumnNames,\n",
        "                                Row_NA_count = self.Row_NA_count,\n",
        "                                plot = True\n",
        "                                )\n",
        "        return TSDATA\n",
        "\n",
        "\n",
        "    def Matric(self,pred, true_y):\n",
        "        args = self.Set_args()\n",
        "        t_df_rs = self.LOAD_TS_FILE.File_loader().copy()\n",
        "        # t_df_rs = self.tsFile.copy()\n",
        "        t_df_rs['date'] = pd.to_datetime(t_df_rs['obsrvn_ymdh'])\n",
        "        t_df_rs = t_df_rs.set_index('date')\n",
        "        t_df_rs = t_df_rs.resample(rule = 'D', kind='timestamp', origin='start').first()\n",
        "        print(f\"t_df_rs.shape : {t_df_rs.shape}\")\n",
        "\n",
        "        num_train = int(len(t_df_rs) * 0.8)\n",
        "        num_test = int(len(t_df_rs) * 0.1)\n",
        "        num_vali = len(t_df_rs) - num_train - num_test\n",
        "        border1 = [0, num_train - args.seq_len, len(t_df_rs) - num_test - args.seq_len]\n",
        "        border2 = [num_train, num_train + num_vali, len(t_df_rs)]\n",
        "\n",
        "        train_data = t_df_rs[border1[0]:border2[0]]\n",
        "\n",
        "        true_step = t_df_rs[border1[2]:border2[2]]\n",
        "        train_step = train_data\n",
        "        self.train_mean = train_step.mean()\n",
        "        self.train_std = train_step.std() + 0.00000001\n",
        "\n",
        "        #prepare\n",
        "        result = pred[:].squeeze()\n",
        "        label = true_y[:].squeeze()\n",
        "\n",
        "        result_scale = (result*self.train_std[args.target]) + self.train_mean[args.target]\n",
        "        label_scale = (label*self.train_std[args.target]) + self.train_mean[args.target]\n",
        "\n",
        "        bk = []\n",
        "        # bk = [ i for i in range(410,434)]\n",
        "        # bk.extend([469,470,475,476,477,478,479,480,])\n",
        "        diff = 0\n",
        "        # diff = diff + len(bk)\n",
        "\n",
        "        #corr\n",
        "        sumout = 0\n",
        "        for id in range(result.shape[0]-diff):\n",
        "          if id in bk:\n",
        "            pass\n",
        "          else:\n",
        "            out,_ = pearsonr(label[id,:],result[id,:])\n",
        "            sumout += out\n",
        "        corr =  sumout/(result.shape[0]-diff)\n",
        "        print(f\"corr : {corr}\")\n",
        "\n",
        "        #MAE\n",
        "        # MAE = mean_absolute_error(label, result)\n",
        "        sumout = 0\n",
        "        for id in range(result.shape[0]-diff):\n",
        "          if id in bk:\n",
        "            pass\n",
        "          else:\n",
        "            out = mean_absolute_error(label[id,:],result[id,:])\n",
        "            sumout += out\n",
        "        MAE = sumout/(result.shape[0]-diff)\n",
        "        print(f\"MAE : {MAE}\")\n",
        "\n",
        "        #MSE\n",
        "        sumout = 0\n",
        "        for id in range(result.shape[0]-diff):\n",
        "          if id in bk:\n",
        "            pass\n",
        "          else:\n",
        "            out = mean_squared_error(label[id,:],result[id,:])\n",
        "            sumout += out\n",
        "        MSE =  sumout/(result.shape[0]-diff)\n",
        "        print(f\"MSE : {MSE}\")\n",
        "\n",
        "        # RMSE (Root Mean Squared Error)\n",
        "        sumout = 0\n",
        "        for id in range(result.shape[0]-diff):\n",
        "          if id in bk:\n",
        "            pass\n",
        "          else:\n",
        "            out = mean_squared_error(label[id,:],result[id,:])\n",
        "            sumout += np.sqrt(out)\n",
        "        RMSE =  sumout/(result.shape[0]-diff)\n",
        "        print(f\"RMSE : {RMSE}\")\n",
        "\n",
        "        #MAPE (Mean Absolute Percentage Error)\n",
        "        sumout = 0\n",
        "        for id in range(result.shape[0]-diff):\n",
        "          if id in bk:\n",
        "            pass\n",
        "          else:\n",
        "            out = np.mean(np.abs((label[id,:] - result[id,:]) / label[id,:])) * 100\n",
        "            sumout += out\n",
        "        norm_MAPE = sumout/(result.shape[0]-diff)\n",
        "        # print(f\"MAPE : {MAPE}\")\n",
        "\n",
        "        #MAPE_scale (Mean Absolute Percentage Error)\n",
        "        sumout = 0\n",
        "        for id in range(result_scale.shape[0]-diff):\n",
        "          if id in bk:\n",
        "            pass\n",
        "          else:\n",
        "            out = np.mean(np.abs((label_scale[id,:] - result_scale[id,:]) / label_scale[id,:])) * 100\n",
        "            sumout += out\n",
        "        MAPE = sumout/(result_scale.shape[0]-diff)\n",
        "        print(f\"denorm_MAPE : {MAPE}\")\n",
        "        # print(f\"error-count : {diff}\")\n",
        "        return MAE, MSE, RMSE, norm_MAPE, MAPE\n",
        "\n",
        "\n",
        "class LOAD_TS_FILE:\n",
        "    def __init__(self, file_path, file_format, file_ix) -> None:\n",
        "        self.file_ix = file_ix\n",
        "        self.file_path = file_path\n",
        "        self.file_format = file_format\n",
        "        self.file_list = [f\"{file}\" for file in os.listdir(self.file_path) if self.file_format in file]\n",
        "        self.fileName = self.file_list[self.file_ix]\n",
        "\n",
        "    def File_loader(self):\n",
        "        if self.file_format == \".csv\":\n",
        "            tsFile = pd.read_csv(os.path.join(self.file_path+self.fileName), header=0)\n",
        "            print(\"fime_name : \",self.fileName ,\" file's shape : \", tsFile.shape)\n",
        "        # else:\n",
        "        #     self.file_format == '.xlsx'\n",
        "        #     tsFile = pd.read_excel(os.path.join(self.file_path+self.fileName), header=0)\n",
        "        #     print(\"fime_name : \",self.fileName ,\" file's shape : \", tsFile.shape)\n",
        "        return tsFile\n"
      ],
      "id": "r8sgv0ZE9Pbj"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njj3TsHF_eXe",
        "outputId": "adb39b11-a2d3-4fe5-ee44-c8eecbb26173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --- Find Files for load : 1\n",
            "\n",
            "\n",
            "=================================================================>> : \n",
            "Total Task file Count.... : 1\n",
            "Processing.... Now ...... : 1\n",
            "=================================================================>> : \n",
            "\n",
            "fime_name :  보조_양수_암반_수질_시.csv  file's shape :  (31767, 36)\n",
            "fime_name :  보조_양수_암반_수질_시.csv  file's shape :  (31767, 36)\n",
            "Use CPU\n",
            ">>>>>>>start training : (UGW)_TT_water_quality_2_양수_DLinear_UGW_water_quality_ftMS_sl72_ll1_pl24_ebtimeF_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "df_raw.cols : Index(['Unnamed: 0', 'well_num', 'obsrvn_ymdh', 'ec', 'wt_temp', 'rainfall',\n",
            "       'wd_temp', 'lev', 'no3n', 'bac', 'cl', 'cd', 'gas', 'cn', 'hg', 'diazn',\n",
            "       'parat', 'phenol', 'pb', 'cr', 'tcet', 'tece', 'tce', 'benzene',\n",
            "       'toluene', 'etilben', 'xylene', 'CA2', 'Mg2', 'Na', 'K', 'NO3', 'SO42',\n",
            "       'CL', 'CO32', 'HCO3'],\n",
            "      dtype='object')\n",
            "df_data.cols : Index(['Unnamed: 0', 'wt_temp', 'rainfall', 'wd_temp', 'ec'], dtype='object')\n",
            "df_data.shape : (31767, 5)\n",
            "train 25318\n",
            "df_raw.cols : Index(['Unnamed: 0', 'well_num', 'obsrvn_ymdh', 'ec', 'wt_temp', 'rainfall',\n",
            "       'wd_temp', 'lev', 'no3n', 'bac', 'cl', 'cd', 'gas', 'cn', 'hg', 'diazn',\n",
            "       'parat', 'phenol', 'pb', 'cr', 'tcet', 'tece', 'tce', 'benzene',\n",
            "       'toluene', 'etilben', 'xylene', 'CA2', 'Mg2', 'Na', 'K', 'NO3', 'SO42',\n",
            "       'CL', 'CO32', 'HCO3'],\n",
            "      dtype='object')\n",
            "df_data.cols : Index(['Unnamed: 0', 'wt_temp', 'rainfall', 'wd_temp', 'ec'], dtype='object')\n",
            "df_data.shape : (31767, 5)\n",
            "val 3155\n",
            "df_raw.cols : Index(['Unnamed: 0', 'well_num', 'obsrvn_ymdh', 'ec', 'wt_temp', 'rainfall',\n",
            "       'wd_temp', 'lev', 'no3n', 'bac', 'cl', 'cd', 'gas', 'cn', 'hg', 'diazn',\n",
            "       'parat', 'phenol', 'pb', 'cr', 'tcet', 'tece', 'tce', 'benzene',\n",
            "       'toluene', 'etilben', 'xylene', 'CA2', 'Mg2', 'Na', 'K', 'NO3', 'SO42',\n",
            "       'CL', 'CO32', 'HCO3'],\n",
            "      dtype='object')\n",
            "df_data.cols : Index(['Unnamed: 0', 'wt_temp', 'rainfall', 'wd_temp', 'ec'], dtype='object')\n",
            "df_data.shape : (31767, 5)\n",
            "test 3153\n",
            "\titers: 100, epoch: 1 | loss: 0.0120018\n",
            "\tspeed: 0.0176s/iter; left time: 1110.7987s\n",
            "\titers: 200, epoch: 1 | loss: 0.0037390\n",
            "\tspeed: 0.0092s/iter; left time: 577.9369s\n",
            "\titers: 300, epoch: 1 | loss: 0.0050037\n",
            "\tspeed: 0.0092s/iter; left time: 577.3443s\n",
            "\titers: 400, epoch: 1 | loss: 0.0178237\n",
            "\tspeed: 0.0090s/iter; left time: 566.3735s\n",
            "\titers: 500, epoch: 1 | loss: 0.0633956\n",
            "\tspeed: 0.0093s/iter; left time: 586.0596s\n",
            "\titers: 600, epoch: 1 | loss: 0.0408440\n",
            "\tspeed: 0.0096s/iter; left time: 604.1864s\n",
            "\titers: 700, epoch: 1 | loss: 0.0124117\n",
            "\tspeed: 0.0102s/iter; left time: 639.0884s\n",
            "\titers: 800, epoch: 1 | loss: 0.0047025\n",
            "\tspeed: 0.0130s/iter; left time: 812.1780s\n",
            "\titers: 900, epoch: 1 | loss: 0.0292877\n",
            "\tspeed: 0.0128s/iter; left time: 798.8704s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0090520\n",
            "\tspeed: 0.0118s/iter; left time: 731.6540s\n",
            "\titers: 1100, epoch: 1 | loss: 0.0159517\n",
            "\tspeed: 0.0154s/iter; left time: 954.7243s\n",
            "\titers: 1200, epoch: 1 | loss: 0.0069696\n",
            "\tspeed: 0.0127s/iter; left time: 788.7352s\n",
            "Epoch: 1 cost time: 14.417806148529053\n",
            "Epoch: 1, Steps: 1265 | Train Loss: 0.3224495 Vali Loss: 1.1637423 Test Loss: 4.9944859\n",
            "Validation loss decreased (inf --> 1.163742).  Saving model ...\n",
            "Updating learning rate to 0.1\n",
            "\titers: 100, epoch: 2 | loss: 0.0017404\n",
            "\tspeed: 0.0469s/iter; left time: 2901.9788s\n",
            "\titers: 200, epoch: 2 | loss: 0.0010611\n",
            "\tspeed: 0.0089s/iter; left time: 552.0830s\n",
            "\titers: 300, epoch: 2 | loss: 0.0045969\n",
            "\tspeed: 0.0090s/iter; left time: 555.6719s\n",
            "\titers: 400, epoch: 2 | loss: 0.0015450\n",
            "\tspeed: 0.0091s/iter; left time: 561.2612s\n",
            "\titers: 500, epoch: 2 | loss: 0.0001964\n",
            "\tspeed: 0.0092s/iter; left time: 567.3303s\n",
            "\titers: 600, epoch: 2 | loss: 0.0399012\n",
            "\tspeed: 0.0106s/iter; left time: 650.0741s\n",
            "\titers: 700, epoch: 2 | loss: 0.0305565\n",
            "\tspeed: 0.0097s/iter; left time: 593.0898s\n",
            "\titers: 800, epoch: 2 | loss: 0.0101389\n",
            "\tspeed: 0.0091s/iter; left time: 559.4115s\n",
            "\titers: 900, epoch: 2 | loss: 0.0019675\n",
            "\tspeed: 0.0109s/iter; left time: 664.3153s\n",
            "\titers: 1000, epoch: 2 | loss: 0.0000609\n",
            "\tspeed: 0.0129s/iter; left time: 784.1340s\n",
            "\titers: 1100, epoch: 2 | loss: 0.0270869\n",
            "\tspeed: 0.0125s/iter; left time: 762.0010s\n",
            "\titers: 1200, epoch: 2 | loss: 0.0032201\n",
            "\tspeed: 0.0126s/iter; left time: 764.7575s\n",
            "Epoch: 2 cost time: 13.520684242248535\n",
            "Epoch: 2, Steps: 1265 | Train Loss: 0.1363824 Vali Loss: 0.0114559 Test Loss: 0.0512932\n",
            "Validation loss decreased (1.163742 --> 0.011456).  Saving model ...\n",
            "Updating learning rate to 0.05\n",
            "\titers: 100, epoch: 3 | loss: 0.0468447\n",
            "\tspeed: 0.0512s/iter; left time: 3103.3147s\n",
            "\titers: 200, epoch: 3 | loss: 0.0108693\n",
            "\tspeed: 0.0089s/iter; left time: 536.1769s\n",
            "\titers: 300, epoch: 3 | loss: 0.0120475\n",
            "\tspeed: 0.0093s/iter; left time: 558.9966s\n",
            "\titers: 400, epoch: 3 | loss: 0.0096814\n",
            "\tspeed: 0.0091s/iter; left time: 545.9672s\n",
            "\titers: 500, epoch: 3 | loss: 0.0059256\n",
            "\tspeed: 0.0089s/iter; left time: 534.0126s\n",
            "\titers: 600, epoch: 3 | loss: 0.0113243\n",
            "\tspeed: 0.0094s/iter; left time: 566.3641s\n",
            "\titers: 700, epoch: 3 | loss: 0.1089605\n",
            "\tspeed: 0.0093s/iter; left time: 556.7626s\n",
            "\titers: 800, epoch: 3 | loss: 0.0022516\n",
            "\tspeed: 0.0092s/iter; left time: 552.8585s\n",
            "\titers: 900, epoch: 3 | loss: 0.0019404\n",
            "\tspeed: 0.0093s/iter; left time: 557.3530s\n",
            "\titers: 1000, epoch: 3 | loss: 0.0025192\n",
            "\tspeed: 0.0102s/iter; left time: 609.7189s\n",
            "\titers: 1100, epoch: 3 | loss: 0.0011605\n",
            "\tspeed: 0.0130s/iter; left time: 773.9010s\n",
            "\titers: 1200, epoch: 3 | loss: 0.0009216\n",
            "\tspeed: 0.0128s/iter; left time: 760.6915s\n",
            "Epoch: 3 cost time: 12.881003379821777\n",
            "Epoch: 3, Steps: 1265 | Train Loss: 0.0189563 Vali Loss: 0.0116198 Test Loss: 0.0513996\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 0.025\n",
            "\titers: 100, epoch: 4 | loss: 0.0024091\n",
            "\tspeed: 0.0534s/iter; left time: 3169.4912s\n",
            "\titers: 200, epoch: 4 | loss: 0.0215310\n",
            "\tspeed: 0.0085s/iter; left time: 506.0490s\n",
            "\titers: 300, epoch: 4 | loss: 0.0001320\n",
            "\tspeed: 0.0090s/iter; left time: 529.9542s\n",
            "\titers: 400, epoch: 4 | loss: 0.0073821\n",
            "\tspeed: 0.0103s/iter; left time: 609.5116s\n",
            "\titers: 500, epoch: 4 | loss: 0.0083561\n",
            "\tspeed: 0.0092s/iter; left time: 541.2078s\n",
            "\titers: 600, epoch: 4 | loss: 0.0019827\n",
            "\tspeed: 0.0092s/iter; left time: 541.6713s\n",
            "\titers: 700, epoch: 4 | loss: 0.0289127\n",
            "\tspeed: 0.0093s/iter; left time: 544.1613s\n",
            "\titers: 800, epoch: 4 | loss: 0.0370792\n",
            "\tspeed: 0.0092s/iter; left time: 540.7477s\n",
            "\titers: 900, epoch: 4 | loss: 0.0004968\n",
            "\tspeed: 0.0093s/iter; left time: 544.8448s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0080165\n",
            "\tspeed: 0.0092s/iter; left time: 537.5254s\n",
            "\titers: 1100, epoch: 4 | loss: 0.0088533\n",
            "\tspeed: 0.0118s/iter; left time: 687.6617s\n",
            "\titers: 1200, epoch: 4 | loss: 0.0011199\n",
            "\tspeed: 0.0123s/iter; left time: 714.1026s\n",
            "Epoch: 4 cost time: 12.710363626480103\n",
            "Epoch: 4, Steps: 1265 | Train Loss: 0.0177401 Vali Loss: 0.0130178 Test Loss: 0.0572298\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Updating learning rate to 0.0125\n",
            "\titers: 100, epoch: 5 | loss: 0.0241956\n",
            "\tspeed: 0.0560s/iter; left time: 3253.6731s\n",
            "\titers: 200, epoch: 5 | loss: 0.0042036\n",
            "\tspeed: 0.0089s/iter; left time: 516.8074s\n",
            "\titers: 300, epoch: 5 | loss: 0.0010661\n",
            "\tspeed: 0.0094s/iter; left time: 546.1918s\n",
            "\titers: 400, epoch: 5 | loss: 0.0040446\n",
            "\tspeed: 0.0094s/iter; left time: 544.2167s\n",
            "\titers: 500, epoch: 5 | loss: 0.0483294\n",
            "\tspeed: 0.0092s/iter; left time: 532.2924s\n",
            "\titers: 600, epoch: 5 | loss: 0.0003893\n",
            "\tspeed: 0.0092s/iter; left time: 529.9546s\n",
            "\titers: 700, epoch: 5 | loss: 0.0063828\n",
            "\tspeed: 0.0088s/iter; left time: 503.9157s\n",
            "\titers: 800, epoch: 5 | loss: 0.0049915\n",
            "\tspeed: 0.0093s/iter; left time: 533.0373s\n",
            "\titers: 900, epoch: 5 | loss: 0.0576975\n",
            "\tspeed: 0.0092s/iter; left time: 527.3719s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0152391\n",
            "\tspeed: 0.0093s/iter; left time: 532.3312s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0001635\n",
            "\tspeed: 0.0094s/iter; left time: 533.8234s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0068917\n",
            "\tspeed: 0.0129s/iter; left time: 734.4106s\n",
            "Epoch: 5 cost time: 12.634014368057251\n",
            "Epoch: 5, Steps: 1265 | Train Loss: 0.0170224 Vali Loss: 0.0117696 Test Loss: 0.0544182\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Updating learning rate to 0.00625\n",
            "\titers: 100, epoch: 6 | loss: 0.0002875\n",
            "\tspeed: 0.0594s/iter; left time: 3374.5788s\n",
            "\titers: 200, epoch: 6 | loss: 0.0041108\n",
            "\tspeed: 0.0104s/iter; left time: 588.2544s\n",
            "\titers: 300, epoch: 6 | loss: 0.0049936\n",
            "\tspeed: 0.0108s/iter; left time: 613.7006s\n",
            "\titers: 400, epoch: 6 | loss: 0.0016813\n",
            "\tspeed: 0.0129s/iter; left time: 729.8046s\n",
            "\titers: 500, epoch: 6 | loss: 0.0136389\n",
            "\tspeed: 0.0126s/iter; left time: 712.7685s\n",
            "\titers: 600, epoch: 6 | loss: 0.0015314\n",
            "\tspeed: 0.0131s/iter; left time: 735.2084s\n",
            "\titers: 700, epoch: 6 | loss: 0.0027912\n",
            "\tspeed: 0.0125s/iter; left time: 704.9661s\n",
            "\titers: 800, epoch: 6 | loss: 0.0273472\n",
            "\tspeed: 0.0126s/iter; left time: 708.6598s\n",
            "\titers: 900, epoch: 6 | loss: 0.0057800\n",
            "\tspeed: 0.0141s/iter; left time: 788.8648s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0117670\n",
            "\tspeed: 0.0138s/iter; left time: 769.2366s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0019382\n",
            "\tspeed: 0.0130s/iter; left time: 727.7379s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0011203\n",
            "\tspeed: 0.0129s/iter; left time: 719.6075s\n",
            "Epoch: 6 cost time: 16.253276348114014\n",
            "Epoch: 6, Steps: 1265 | Train Loss: 0.0164372 Vali Loss: 0.0120255 Test Loss: 0.0552437\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Updating learning rate to 0.003125\n",
            "\titers: 100, epoch: 7 | loss: 0.0149784\n",
            "\tspeed: 0.0526s/iter; left time: 2922.0313s\n",
            "\titers: 200, epoch: 7 | loss: 0.0068759\n",
            "\tspeed: 0.0089s/iter; left time: 491.7213s\n",
            "\titers: 300, epoch: 7 | loss: 0.0077231\n",
            "\tspeed: 0.0095s/iter; left time: 524.0704s\n",
            "\titers: 400, epoch: 7 | loss: 0.0159873\n",
            "\tspeed: 0.0097s/iter; left time: 538.0258s\n",
            "\titers: 500, epoch: 7 | loss: 0.0015104\n",
            "\tspeed: 0.0092s/iter; left time: 509.4469s\n",
            "\titers: 600, epoch: 7 | loss: 0.0138287\n",
            "\tspeed: 0.0093s/iter; left time: 513.4667s\n",
            "\titers: 700, epoch: 7 | loss: 0.0018182\n",
            "\tspeed: 0.0095s/iter; left time: 523.8389s\n",
            "\titers: 800, epoch: 7 | loss: 0.0046768\n",
            "\tspeed: 0.0093s/iter; left time: 510.7058s\n",
            "\titers: 900, epoch: 7 | loss: 0.0101676\n",
            "\tspeed: 0.0090s/iter; left time: 494.9610s\n",
            "\titers: 1000, epoch: 7 | loss: 0.0135697\n",
            "\tspeed: 0.0113s/iter; left time: 616.0280s\n",
            "\titers: 1100, epoch: 7 | loss: 0.0051607\n",
            "\tspeed: 0.0130s/iter; left time: 707.9365s\n",
            "\titers: 1200, epoch: 7 | loss: 0.0082290\n",
            "\tspeed: 0.0131s/iter; left time: 713.0376s\n",
            "Epoch: 7 cost time: 13.327643871307373\n",
            "Epoch: 7, Steps: 1265 | Train Loss: 0.0161935 Vali Loss: 0.0100394 Test Loss: 0.0455813\n",
            "Validation loss decreased (0.011456 --> 0.010039).  Saving model ...\n",
            "Updating learning rate to 0.0015625\n",
            "\titers: 100, epoch: 8 | loss: 0.0046348\n",
            "\tspeed: 0.0556s/iter; left time: 3017.3667s\n",
            "\titers: 200, epoch: 8 | loss: 0.0021159\n",
            "\tspeed: 0.0090s/iter; left time: 488.4285s\n",
            "\titers: 300, epoch: 8 | loss: 0.1206687\n",
            "\tspeed: 0.0094s/iter; left time: 507.3422s\n",
            "\titers: 400, epoch: 8 | loss: 0.0024230\n",
            "\tspeed: 0.0091s/iter; left time: 490.5072s\n",
            "\titers: 500, epoch: 8 | loss: 0.0199905\n",
            "\tspeed: 0.0093s/iter; left time: 502.6250s\n",
            "\titers: 600, epoch: 8 | loss: 0.0012607\n",
            "\tspeed: 0.0093s/iter; left time: 502.1317s\n",
            "\titers: 700, epoch: 8 | loss: 0.0038450\n",
            "\tspeed: 0.0093s/iter; left time: 498.5512s\n",
            "\titers: 800, epoch: 8 | loss: 0.0018967\n",
            "\tspeed: 0.0094s/iter; left time: 504.9571s\n",
            "\titers: 900, epoch: 8 | loss: 0.0097754\n",
            "\tspeed: 0.0093s/iter; left time: 495.1738s\n",
            "\titers: 1000, epoch: 8 | loss: 0.0014685\n",
            "\tspeed: 0.0099s/iter; left time: 529.2662s\n",
            "\titers: 1100, epoch: 8 | loss: 0.0092545\n",
            "\tspeed: 0.0132s/iter; left time: 704.0260s\n",
            "\titers: 1200, epoch: 8 | loss: 0.0103400\n",
            "\tspeed: 0.0130s/iter; left time: 692.0185s\n",
            "Epoch: 8 cost time: 13.114068269729614\n",
            "Epoch: 8, Steps: 1265 | Train Loss: 0.0159072 Vali Loss: 0.0103522 Test Loss: 0.0469858\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 0.00078125\n",
            "\titers: 100, epoch: 9 | loss: 0.0035404\n",
            "\tspeed: 0.0550s/iter; left time: 2915.3047s\n",
            "\titers: 200, epoch: 9 | loss: 0.0006939\n",
            "\tspeed: 0.0090s/iter; left time: 476.8773s\n",
            "\titers: 300, epoch: 9 | loss: 0.0006007\n",
            "\tspeed: 0.0096s/iter; left time: 505.4302s\n",
            "\titers: 400, epoch: 9 | loss: 0.0045038\n",
            "\tspeed: 0.0094s/iter; left time: 496.9200s\n",
            "\titers: 500, epoch: 9 | loss: 0.0005646\n",
            "\tspeed: 0.0094s/iter; left time: 495.7250s\n",
            "\titers: 600, epoch: 9 | loss: 0.0012056\n",
            "\tspeed: 0.0092s/iter; left time: 483.1329s\n",
            "\titers: 700, epoch: 9 | loss: 0.0038641\n",
            "\tspeed: 0.0093s/iter; left time: 488.9771s\n",
            "\titers: 800, epoch: 9 | loss: 0.0244701\n",
            "\tspeed: 0.0093s/iter; left time: 488.0370s\n",
            "\titers: 900, epoch: 9 | loss: 0.0506190\n",
            "\tspeed: 0.0093s/iter; left time: 486.1051s\n",
            "\titers: 1000, epoch: 9 | loss: 0.0021322\n",
            "\tspeed: 0.0094s/iter; left time: 489.5774s\n",
            "\titers: 1100, epoch: 9 | loss: 0.2880135\n",
            "\tspeed: 0.0139s/iter; left time: 722.7266s\n",
            "\titers: 1200, epoch: 9 | loss: 0.0119106\n",
            "\tspeed: 0.0127s/iter; left time: 661.9727s\n",
            "Epoch: 9 cost time: 13.090036869049072\n",
            "Epoch: 9, Steps: 1265 | Train Loss: 0.0156275 Vali Loss: 0.0105222 Test Loss: 0.0478439\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Updating learning rate to 0.000390625\n",
            "\titers: 100, epoch: 10 | loss: 0.0024677\n",
            "\tspeed: 0.0575s/iter; left time: 2978.8220s\n",
            "\titers: 200, epoch: 10 | loss: 0.0007653\n",
            "\tspeed: 0.0092s/iter; left time: 475.1374s\n",
            "\titers: 300, epoch: 10 | loss: 0.0269110\n",
            "\tspeed: 0.0094s/iter; left time: 483.4326s\n",
            "\titers: 400, epoch: 10 | loss: 0.0183053\n",
            "\tspeed: 0.0091s/iter; left time: 470.7924s\n",
            "\titers: 500, epoch: 10 | loss: 0.0006914\n",
            "\tspeed: 0.0092s/iter; left time: 473.3881s\n",
            "\titers: 600, epoch: 10 | loss: 0.0192805\n",
            "\tspeed: 0.0093s/iter; left time: 478.5038s\n",
            "\titers: 700, epoch: 10 | loss: 0.0039999\n",
            "\tspeed: 0.0096s/iter; left time: 493.5783s\n",
            "\titers: 800, epoch: 10 | loss: 0.0019690\n",
            "\tspeed: 0.0096s/iter; left time: 490.6712s\n",
            "\titers: 900, epoch: 10 | loss: 0.0017035\n",
            "\tspeed: 0.0091s/iter; left time: 463.6083s\n",
            "\titers: 1000, epoch: 10 | loss: 0.0006847\n",
            "\tspeed: 0.0091s/iter; left time: 464.4256s\n",
            "\titers: 1100, epoch: 10 | loss: 0.0024513\n",
            "\tspeed: 0.0106s/iter; left time: 539.5465s\n",
            "\titers: 1200, epoch: 10 | loss: 0.0152344\n",
            "\tspeed: 0.0131s/iter; left time: 661.2014s\n",
            "Epoch: 10 cost time: 12.91309666633606\n",
            "Epoch: 10, Steps: 1265 | Train Loss: 0.0155416 Vali Loss: 0.0102593 Test Loss: 0.0465597\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Updating learning rate to 0.0001953125\n",
            "\titers: 100, epoch: 11 | loss: 0.0009910\n",
            "\tspeed: 0.0588s/iter; left time: 2970.9891s\n",
            "\titers: 200, epoch: 11 | loss: 0.0022510\n",
            "\tspeed: 0.0092s/iter; left time: 462.3624s\n",
            "\titers: 300, epoch: 11 | loss: 0.0044514\n",
            "\tspeed: 0.0094s/iter; left time: 471.8573s\n",
            "\titers: 400, epoch: 11 | loss: 0.0004273\n",
            "\tspeed: 0.0091s/iter; left time: 456.4493s\n",
            "\titers: 500, epoch: 11 | loss: 0.0013770\n",
            "\tspeed: 0.0093s/iter; left time: 464.3393s\n",
            "\titers: 600, epoch: 11 | loss: 0.0051922\n",
            "\tspeed: 0.0096s/iter; left time: 477.9719s\n",
            "\titers: 700, epoch: 11 | loss: 0.0018024\n",
            "\tspeed: 0.0092s/iter; left time: 457.3740s\n",
            "\titers: 800, epoch: 11 | loss: 0.0020863\n",
            "\tspeed: 0.0093s/iter; left time: 461.4013s\n",
            "\titers: 900, epoch: 11 | loss: 0.0163059\n",
            "\tspeed: 0.0103s/iter; left time: 512.2832s\n",
            "\titers: 1000, epoch: 11 | loss: 0.0203648\n",
            "\tspeed: 0.0092s/iter; left time: 455.7910s\n",
            "\titers: 1100, epoch: 11 | loss: 0.0084794\n",
            "\tspeed: 0.0100s/iter; left time: 492.9362s\n",
            "\titers: 1200, epoch: 11 | loss: 0.0035327\n",
            "\tspeed: 0.0131s/iter; left time: 645.8251s\n",
            "Epoch: 11 cost time: 12.983690977096558\n",
            "Epoch: 11, Steps: 1265 | Train Loss: 0.0154524 Vali Loss: 0.0104135 Test Loss: 0.0472080\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Updating learning rate to 9.765625e-05\n",
            "\titers: 100, epoch: 12 | loss: 0.0014441\n",
            "\tspeed: 0.0589s/iter; left time: 2898.9774s\n",
            "\titers: 200, epoch: 12 | loss: 0.0049020\n",
            "\tspeed: 0.0097s/iter; left time: 475.3051s\n",
            "\titers: 300, epoch: 12 | loss: 0.0008377\n",
            "\tspeed: 0.0098s/iter; left time: 480.1034s\n",
            "\titers: 400, epoch: 12 | loss: 0.0158822\n",
            "\tspeed: 0.0100s/iter; left time: 490.1878s\n",
            "\titers: 500, epoch: 12 | loss: 0.0041351\n",
            "\tspeed: 0.0098s/iter; left time: 480.6722s\n",
            "\titers: 600, epoch: 12 | loss: 0.0374030\n",
            "\tspeed: 0.0094s/iter; left time: 459.5213s\n",
            "\titers: 700, epoch: 12 | loss: 0.0007109\n",
            "\tspeed: 0.0094s/iter; left time: 458.9465s\n",
            "\titers: 800, epoch: 12 | loss: 0.0302998\n",
            "\tspeed: 0.0090s/iter; left time: 434.8819s\n",
            "\titers: 900, epoch: 12 | loss: 0.0011274\n",
            "\tspeed: 0.0093s/iter; left time: 451.5686s\n",
            "\titers: 1000, epoch: 12 | loss: 0.0012608\n",
            "\tspeed: 0.0094s/iter; left time: 452.2676s\n",
            "\titers: 1100, epoch: 12 | loss: 0.0012365\n",
            "\tspeed: 0.0106s/iter; left time: 509.0261s\n",
            "\titers: 1200, epoch: 12 | loss: 0.0487917\n",
            "\tspeed: 0.0133s/iter; left time: 641.1792s\n",
            "Epoch: 12 cost time: 13.318132638931274\n",
            "Epoch: 12, Steps: 1265 | Train Loss: 0.0154158 Vali Loss: 0.0104155 Test Loss: 0.0473379\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            ">>>>>>>testing : (UGW)_TT_water_quality_2_양수_DLinear_UGW_water_quality_ftMS_sl72_ll1_pl24_ebtimeF_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "df_raw.cols : Index(['Unnamed: 0', 'well_num', 'obsrvn_ymdh', 'ec', 'wt_temp', 'rainfall',\n",
            "       'wd_temp', 'lev', 'no3n', 'bac', 'cl', 'cd', 'gas', 'cn', 'hg', 'diazn',\n",
            "       'parat', 'phenol', 'pb', 'cr', 'tcet', 'tece', 'tce', 'benzene',\n",
            "       'toluene', 'etilben', 'xylene', 'CA2', 'Mg2', 'Na', 'K', 'NO3', 'SO42',\n",
            "       'CL', 'CO32', 'HCO3'],\n",
            "      dtype='object')\n",
            "df_data.cols : Index(['Unnamed: 0', 'wt_temp', 'rainfall', 'wd_temp', 'ec'], dtype='object')\n",
            "df_data.shape : (31767, 5)\n",
            "test 3153\n",
            "mse:0.04558132588863373, mae:0.11298173666000366, rse:0.7524851560592651, corr:[0.93347347 0.9250757  0.91995203 0.91527736 0.91044533 0.90498334\n",
            " 0.90178746 0.89879245 0.89587003 0.8939264  0.893144   0.89101106\n",
            " 0.89015186 0.8886496  0.88707274 0.88662124 0.8858287  0.88591325\n",
            " 0.88487715 0.8842267  0.88335377 0.88273317 0.8816553  0.88083136]\n",
            "fime_name :  보조_양수_암반_수질_시.csv  file's shape :  (31767, 36)\n",
            "fime_name :  보조_양수_암반_수질_시.csv  file's shape :  (31767, 36)\n",
            "t_df_rs.shape : (1324, 36)\n",
            "corr : nan\n",
            "MAE : 0.11298173245357329\n",
            "MSE : 0.045581324236461766\n",
            "RMSE : 0.1325189904820702\n",
            "denorm_MAPE : 8.201914530419478\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TS_DATA(Id=1, ob_num=2, ob_id='보조', ob_name='양수', Modi_Date=datetime.datetime(2023, 11, 12, 6, 33, 58, 72007), FileName='보조_양수_암반_수질_시.csv', FilePath='/content/drive/MyDrive/NIA 2차 수질예측 프로젝트/NIA_AIDEN_07_(지하수)/수질(Total)/추가_수질_데이터(1209)/2. 수질 데이터셋(1209)_재정제/', Row_count=31767, MAE=0.11298173245357329, MSE=0.045581324236461766, RMSE=0.1325189904820702, norm_MAPE=66.90074673444877, MAPE=8.201914530419478, ColumnNames=['Unnamed: 0', 'well_num', 'obsrvn_ymdh', 'ec', 'wt_temp', 'rainfall', 'wd_temp', 'lev', 'no3n', 'bac', 'cl', 'cd', 'gas', 'cn', 'hg', 'diazn', 'parat', 'phenol', 'pb', 'cr', 'tcet', 'tece', 'tce', 'benzene', 'toluene', 'etilben', 'xylene', 'CA2', 'Mg2', 'Na', 'K', 'NO3', 'SO42', 'CL', 'CO32', 'HCO3'], Row_NA_count=[0, 0, 0, 0, 0, 0, 0, 0, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767, 31767], plot=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "\n",
        "## 코드 실행을 위한 쉘.\n",
        "\n",
        "# 데이터가 있는 위치 폴더를 경로 입력\n",
        "file_path = \"/content/drive/MyDrive/NIA 2차 수질예측 프로젝트/NIA_AIDEN_07_(지하수)/수질(Total)/추가_수질_데이터(1209)/2. 수질 데이터셋(1209)_재정제/\"\n",
        "# 결과 파일이 출력될 폴더 경로 입력\n",
        "save_path = \"/content/drive/MyDrive/NIA 2차 수질예측 프로젝트/NIA_AIDEN_07_(지하수)/수질(Total)/\"\n",
        "# 읽어올 파일 format 조작하지 않아도 됨.\n",
        "file_format = \".csv\"\n",
        "# 출력될 엑셀 파일 이름 지정\n",
        "fxls_name =  \"UGW_DLinear_TT_water_quality_1209_(data_fix)_02.xlsx\"\n",
        "# 출력될 엑셀 파일의 sheet명\n",
        "sheet_name = \"TT_water_quality\"\n",
        "sheet_col = \"\"\n",
        "\n",
        "autoAR = TSFAR(file_path, save_path, file_format, fxls_name, sheet_name, sheet_col)\n",
        "autoAR.TS_DATA_ANLYS_FILES()"
      ],
      "id": "njj3TsHF_eXe"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jqTHO1UEJ0vm"
      },
      "id": "jqTHO1UEJ0vm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hENfgF8PKg9-"
      },
      "id": "hENfgF8PKg9-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Nj-QYn34KhRs"
      },
      "id": "Nj-QYn34KhRs"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}